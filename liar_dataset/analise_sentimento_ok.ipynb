{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analise_sentimento_ok.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagorainmaker77/liar_dataset/blob/master/analise_sentimento_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6Ea_3O-qaj32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "47f8a2ad-9b99-493a-df2d-2dc37a6ae45e"
      },
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (1.0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SlBb7LodTqP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "cbf33833-0fa7-4909-c036-d83e517329c9"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "import string\n",
        "import nltk\n",
        "from nltk import PorterStemmer\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "from gensim import corpora\n",
        "import gensim\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ch-a61ODUTE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
        "uri_valid  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/valid.tsv'\n",
        "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
        "\n",
        "    \n",
        "df_train = pd.read_table(uri_train,\n",
        "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
        "\n",
        "    \n",
        "df_valid = pd.read_table(uri_valid,\n",
        "                             names =['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
        "\n",
        "\n",
        "df_test = pd.read_csv(uri_test, sep='\\t', \n",
        "                            names =['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue']) \n",
        "\n",
        "\n",
        "df = pd.concat([df_train, df_valid])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3268GrRUvtA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "liar_list = [df,df_test]\n",
        "\n",
        "n = 10\n",
        "\n",
        "subject = liar_list[0].groupby(['subject']).count().label.sort_values(ascending=False)[:n].index.tolist()\n",
        "speaker = liar_list[0].groupby(['speaker']).count().label.sort_values(ascending=False)[:n].index.tolist()\n",
        "job = liar_list[0].groupby(['job']).count().label.sort_values(ascending=False)[:n].index.tolist()\n",
        "state = liar_list[0].groupby(['state']).count().label.sort_values(ascending=False)[:n].index.tolist()\n",
        "party = liar_list[0].groupby(['party']).count().label.sort_values(ascending=False)[:n].index.tolist()\n",
        "venue = liar_list[0].groupby(['venue']).count().label.sort_values(ascending=False)[:n].index.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3X3QP4RUhUDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MultiColumnLabelEncoder:\n",
        "  \n",
        "  \n",
        "    countV = CountVectorizer(analyzer='word', binary=True, decode_error='strict', encoding='utf-8', input='content',\n",
        "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
        "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)\n",
        "    \n",
        "    def __init__(self,columns = None):\n",
        "        self.columns = columns # array of column names to encode\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        return self # not relevant here\n",
        "\n",
        "    def transform(self,X):\n",
        "        '''\n",
        "        Transforms columns of X specified in self.columns using\n",
        "        LabelEncoder(). If no columns specified, transforms all\n",
        "        columns in X.\n",
        "        '''\n",
        "        output = X.copy()\n",
        "        if self.columns is not None:\n",
        "            for col in self.columns:\n",
        "                output[col] = countV().fit_transform(output[col])\n",
        "        else:\n",
        "            for colname,col in output.iteritems():\n",
        "                output[colname] = countV().fit_transform(col)\n",
        "        return output\n",
        "\n",
        "    def fit_transform(self,X,y=None):\n",
        "        return self.fit(X,y).transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVUVl7D-WYvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_of_interest = state+subject+speaker+party+venue+job\n",
        "to_encode = [('speaker',speaker),\n",
        "            ('party',party),\n",
        "            ('subject',subject),\n",
        "            ('state',state),\n",
        "            ('venue',venue),\n",
        "            ('job',job)]\n",
        "for i in liar_list:\n",
        "    for var in to_encode:\n",
        "        for value in var[1]:\n",
        "            i[value] = i[var[0]].apply(lambda x: x==value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKvnX_GhWz46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "truth = {'false':0.,'half-true':0.5,'mostly-true':0.75,'true':1.,'pants-fire':-0.25,'barely-true':0.25} \n",
        "\n",
        "\n",
        "for i in liar_list:\n",
        "    i['numer_truth'] = i['label'].apply(lambda x: truth[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kqQJrjfskIPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def score(file):\n",
        "  data_pre = pd.read_csv(file, sep='\\n', names = [\"label\"]) \n",
        "  score = f1_score(df_test['label'],data_pre, average='micro')\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHE-8CBdXZFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "ps = PorterStemmer()\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def clean_stem (sent, seq=False):\n",
        "    temp1=sent\n",
        "    temp2 = re.split('\\W+',temp1)\n",
        "    temp3 = [ps.stem(x) for x in temp2 if x not in stopwords]\n",
        "    return temp3\n",
        "def sentiment(x):\n",
        "    score = sid.polarity_scores(x)\n",
        "    return score['compound']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nPxdVRKtYSkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in liar_list:\n",
        "    i['sentiment'] = i['statement'].apply(lambda x: sentiment(' '.join(clean_stem(x))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gMSPFemgY7mI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test['sentiment'] = df_test['statement'].apply(lambda x: sentiment(' '.join(clean_stem(x))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J17BdtpUjVkZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "countV = CountVectorizer(analyzer='word', binary=True, decode_error='strict', encoding='utf-8', input='content',\n",
        "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
        "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yiBzdtzknrrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa691519-e0e6-4a0c-db8a-a230ce704432"
      },
      "cell_type": "code",
      "source": [
        "countV.fit_transform(df['statement'].values)\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11524x12590 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 114275 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "bc16o9-dnnF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "nb_cv = Pipeline([\n",
        "        ('NBCV', countV),\n",
        "        ('nb_clf', MultinomialNB(alpha=1.5, class_prior=None, fit_prior=True))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hmj6zOg5j-LO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "7ceae854-6525-4001-f77d-76fdb76133a8"
      },
      "cell_type": "code",
      "source": [
        "nb_cv.fit(df['statement'] + df['sentiment'],df['label'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not float",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 result[mask] = op(xrav[mask],\n\u001b[0;32m-> 1009\u001b[0;31m                                   com.values_from_object(yrav[mask]))\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not float",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-e5a45bc3adbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m         return construct_result(left, result,\n\u001b[1;32m   1585\u001b[0m                                 index=left.index, name=res_name, dtype=None)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/algos.pyx\u001b[0m in \u001b[0;36mpandas._libs.algos.arrmap\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U82') dtype('<U82') dtype('<U82')"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sFYOML4CnSGh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "arquivo = 'best_result.txt'\n",
        "\n",
        "vf = open(file, 'w+')\n",
        "for index, row in df_test.iterrows():\n",
        "  text = {row['statement'].add(row['sentiment'])}\n",
        "  pred_a = class_a.predict(text)\n",
        "  prend = pred_a[0]   \n",
        "  vf.write(str(prend)+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2rePeIgkqHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c01b41b9-8efb-40ea-aeee-957fc36f9303"
      },
      "cell_type": "code",
      "source": [
        "print(score(arquivo))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2628255722178374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbFnYqG6liRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "347f8e61-e7e8-4184-db48-7a0771607136"
      },
      "cell_type": "code",
      "source": [
        "countV.fit_transform(df['statement'].values)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11524x12590 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 114275 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "4Ya9dKwklrAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_cv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}